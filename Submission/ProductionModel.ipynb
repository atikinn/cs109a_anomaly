{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exchangeability Martingale Model for Time Series Anomaly Detection\n",
    "**Harvard University**<br>\n",
    "**Fall 2016**<br>\n",
    "**Instructors: W. Pan, P. Protopapas, K. Rader**<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "**Dennis Milechin, Ivan Sinyagin, Hany Bassily**\n",
    "\n",
    "<br>\n",
    "## Production Code\n",
    "\n",
    "ver 1.0 12/14/2016 Bassily H., Sinyagin I. and Milechin D.\n",
    "\n",
    "\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions:\n",
    "\n",
    "<br>\n",
    "This code calculate the exchangeabiliy martingale, the change detection difference martingale and the smoothed changed detection difference martingale.\n",
    "\n",
    "It performs the martingale computation based on three methods, the power martingale with predefined epsilon value, the mix power martingale and the plugin martingale. The user can choose which method to be used to calculate the three model outputs.\n",
    "\n",
    "For the strangeness measure, the user can choose between 3 methods if the data is single vararaible. The three options are the distance, the standard deviation or the jump rate. If the data is multivariate, only the distance will be consider regardless what selection the user has chosen\n",
    "\n",
    "### Input:\n",
    "\n",
    "The code accepts as input two Numeric only csv files. The first includes the data that will be used as training and the second is the test data\n",
    "\n",
    "### Calculation Method:\n",
    "\n",
    "The calculation follows the following steps:\n",
    " - Data preprocessing where two procedures are available where the user can choose either or both. The first is a normalization procedure where both datasets are normalized by their respective standard deviation\n",
    " \n",
    " - The second preprocessing is the application of a time lag diference filter where the user can specify the amount of lag to be applied for the difference\n",
    " \n",
    " - The preprocessed data is then admitted to the martingale calculation algorithm implemented as per Fedorova et al., 2012. The algorithm starts by the calculation of the strangeness measure according to the user selection then the p-value computation and the martingale evaluation according to which martingale method the user selected.\n",
    " \n",
    " - Each martingale type has its own seperate function\n",
    " \n",
    " - The outcome of this step is the logarithmic martingale which is subsequently used in calculating the changedetction measure based on the difference between two consecutive martingale\n",
    " \n",
    " - A smoothing function is then applied to the resulting change detection measure which applies an exponential filter to better use the result for thresholding and persistence evaluation if needed\n",
    " \n",
    " - For the mix martingale, a numeric integration algorithm is used. For which, discrete values of the epsilon domain should be specified. For this purpose a \"resolution\" term is introduced and specified by the user to define how fine the epsilon domain can be discretesized.\n",
    " \n",
    "### Options:\n",
    "\n",
    "The user has to define the following:\n",
    "\n",
    " - A full pathh to the training and test data files\n",
    " - Selection whether the data to be normalized or not\n",
    " - Selection if a lag difference filter should be applied or not and the desired lag\n",
    " - The selection of the starngeness function (wil be overriden id the data is multivariate)\n",
    " - The type of martingale function\n",
    " - The value of epsilon to be used with the predefined epsilon power martingale method\n",
    " - The resolution for the integartion of the mixed martingale\n",
    " - The smootheness factor\n",
    " \n",
    "### Output\n",
    "\n",
    "The output of the program is a csv file which includes three columns:\n",
    "\n",
    " - The calculated martingale\n",
    " - The change detection difference value\n",
    " - The smoothed changed detection difference value\n",
    " \n",
    "### Directions:\n",
    "\n",
    " - First step clean the data and prepare to csv files. One includes the training set and the second the test set\n",
    " - Open the ipython notebook and fill the options sections with all required detail. Please adhere to the syntax indicated for each option\n",
    " - run the model and the output file will begenerat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import time\n",
    "from scipy.integrate import simps\n",
    "\n",
    "from inspect import getmembers\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import gaussian_kde as PDF\n",
    "\n",
    "import collections\n",
    "from matplotlib import rcParams\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**---**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Options\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Options to be specified by the user:\n",
    "# ------------------------------------\n",
    "\n",
    "'''This section is used to specify all the entries required to run the model:\n",
    "\n",
    "        1- Full path of the training dataset\n",
    "        2- Full path of the test dataset\n",
    "        3- The required preprocessing (Normalization - Difference)\n",
    "        4- The type of strangeness function needed (select between three types)\n",
    "        5- The type of martingale required (Power - Mix - Plugin)\n",
    "        6- The value of Epsilon to be used for the Power Martingale with predefined Epsilon\n",
    "        7- The smoothing power for the change detection\n",
    "        8- The resolution for the mix martingale integration which is the number of slices the interval of \n",
    "           [0,1] will be divided to - Vovk et al., 2003 '''\n",
    "\n",
    "# Training data file\n",
    "file_train = 'datasets/4205872016.csv'\n",
    "\n",
    "# Test data file\n",
    "file_test = 'datasets/4205882016.csv'\n",
    "\n",
    "# Normalization required [y/n] ?\n",
    "normal = 'y'\n",
    "\n",
    "# Difference required (enter required delay or 'No' if no difference is needed ?\n",
    "dif = 15\n",
    "\n",
    "# Type of strangeness function ( Distance = 1, Standard Deviation = 2 , Jump rate = 3)\n",
    "strg = 3\n",
    "\n",
    "# Type of Martingale to be calculated:\n",
    "#         Predefined Epsilon = 'eps'\n",
    "#         Mixed Martingale   = 'mix' \n",
    "#         Plugin Martingale  = 'plg'\n",
    "mart = 'eps'\n",
    "\n",
    "# the value of Epsilon to be used for the Power Martingale with predefined Epsilon [0,1]\n",
    "eps = 0.3\n",
    "\n",
    "# Mixed Martingale Integration Resolution (i.e. the number of slices the interval [0,1] will be divided to to \n",
    "# integrate over all Epsilon values - Vovk et al., 2003)\n",
    "res = 100\n",
    "\n",
    "# Smoothing power of the filer [0,1]\n",
    "a = 0.008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. General Functions\n",
    "\n",
    "<br>\n",
    "### 2.1 Power Martingale with Predefined Epsilon Value\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to calculate Power Martingale - Single Epsilon:\n",
    "# -------------------------------------------------------\n",
    "# power_martingale function\n",
    "# Description: Calculates Power Martingale for outlier detection\n",
    "# Input:\n",
    "#       train - numpy matrix containing the training data set\n",
    "#       test - numpy matrix containing the testing data set\n",
    "#       eps - epsilon value\n",
    "#       alpha_flag - 1,2,3\n",
    "# Return:\n",
    "#       datpower_mart - Power Martingale Value\n",
    "#       diff_arr - Power Martingale Value Difference\n",
    "#\n",
    "def power_martingale(train , test , eps , alpha_flag):\n",
    " \n",
    "    # data mean\n",
    "    mean = np.average(train , axis = 0)\n",
    "    \n",
    "    # mean vector norm\n",
    "    mean_norm = np.linalg.norm(mean)\n",
    "\n",
    "    # strangenes reference for distance\n",
    "    ref_alpha = np.linalg.norm(train.std(axis = 0)) + mean_norm\n",
    "\n",
    "    # Data shape\n",
    "    L = test.shape[0]\n",
    "    col = test.shape[1]\n",
    "    \n",
    "    # Only the distance strangeness is available for multivariate data\n",
    "    if col>1:\n",
    "        alpha_flag = 1\n",
    "    \n",
    "    # alpha\n",
    "    if alpha_flag == 1:\n",
    "        alpha = np.linalg.norm(test , axis = 1) / ref_alpha\n",
    "        \n",
    "    elif alpha_flag == 2:\n",
    "        alpha = np.absolute(test - np.average(train)) /  train.std(axis=0)\n",
    "        \n",
    "    else:\n",
    "        alpha = alpha_calc(train , test)\n",
    "\n",
    "    # p-value(randomised)\n",
    "    p_value = np.ones(alpha.shape)\n",
    "\n",
    "    # iterrate for p-value calculation\n",
    "    for i in range(1,L):\n",
    "    \n",
    "        # end value\n",
    "        end = alpha[i]\n",
    "    \n",
    "        # alpha subset\n",
    "        alpha_sub = alpha[:i + 1]\n",
    "\n",
    "        # number of elements\n",
    "        n = i + 1   \n",
    "    \n",
    "        # p-values calculation\n",
    "        np.random.seed(200)\n",
    "        p_value[i] = ( float(np.sum(alpha_sub > end)) + np.random.uniform() * np.sum(alpha_sub == end ) ) / float(n)\n",
    "    \n",
    "        # to avoid log zero\n",
    "        p_value[p_value==0] = 0.0000000001\n",
    "    \n",
    "    # initiate Power Martingale\n",
    "    power_mart = np.zeros(alpha.shape)\n",
    "\n",
    "    # dummy multiplier\n",
    "    M = 0.\n",
    "    \n",
    "    # initiate difference measure\n",
    "    diff_arr = np.zeros((L,))\n",
    "\n",
    "    # iterrate for power martingale calculation\n",
    "    for i in range(L):\n",
    "        \n",
    "        # increment\n",
    "        delta = eps * (p_value[i]) ** (eps - 1.)\n",
    "        \n",
    "        # Calculate martingale difference\n",
    "        diff_arr[i] = np.absolute(np.log(delta))\n",
    "        \n",
    "        # Update power martingal\n",
    "        M += np.log(delta)  \n",
    "        \n",
    "        # Array\n",
    "        power_mart[i] = M\n",
    "        \n",
    "    return power_mart , diff_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Mixed Power Martingale\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to calculate Mix Power Martingale:\n",
    "# -------------------------------------------\n",
    "# power_martingale_mix function\n",
    "# Description: Calculates Power Martingale for outlier detection with mixture\n",
    "# Input:\n",
    "#       train - numpy matrix containing the training data set\n",
    "#       test - numpy matrix containing the testing data set\n",
    "#       res - Resolution of the uniform distribution for integrating epsilon values.\n",
    "#       alpha_flag - 1,2,3\n",
    "# Return:\n",
    "#       datpower_mart - Power Martingale Value\n",
    "#       diff_arr - Power Martingale Value Difference\n",
    "#\n",
    "def power_martingale_mix(train, test , res, alpha_flag):\n",
    "    \n",
    "    # epsilon array\n",
    "    eps = np.linspace(0.001, 0.999, res)\n",
    "    \n",
    "    # data mean\n",
    "    mean = np.average(train , axis = 0)\n",
    "    \n",
    "    # mean vector norm\n",
    "    mean_norm = np.linalg.norm(mean)\n",
    "\n",
    "    # strangenes reference for distance\n",
    "    ref_alpha = np.linalg.norm(train.std(axis = 0)) + mean_norm\n",
    "    \n",
    "\n",
    "    # Data shape\n",
    "    L = test.shape[0]\n",
    "    col = test.shape[1]\n",
    "    \n",
    "    # Only the distance strangeness is available for multivariate data\n",
    "    if col>1:\n",
    "        alpha_flag = 1\n",
    "\n",
    "    # alpha\n",
    "    if alpha_flag == 1:\n",
    "        alpha = np.linalg.norm(test, axis = 1) / ref_alpha\n",
    "        \n",
    "    elif alpha_flag == 2:\n",
    "        alpha = np.absolute(test - np.average(train)) /  train.std(axis=0)\n",
    "        \n",
    "    else:\n",
    "        alpha = alpha_calc(train , test)\n",
    "    \n",
    "\n",
    "    # p-value(randomised)\n",
    "    p_value = np.ones(alpha.shape)\n",
    "\n",
    "    # iterrate for p-value calculation\n",
    "    for i in range(1,L):\n",
    "    \n",
    "        # end value\n",
    "        end = alpha[i]\n",
    "    \n",
    "        # alpha subset\n",
    "        alpha_sub = alpha[:i - 1]\n",
    "\n",
    "        # number of elements\n",
    "        n = i + 1   \n",
    "    \n",
    "        # p-values calculation\n",
    "        np.random.seed(200)\n",
    "        p_value[i] = ( float(np.sum(alpha_sub > end)) + np.random.uniform() * np.sum(alpha_sub == end ) ) / float(n)\n",
    "    \n",
    "        # to avoid log zero\n",
    "        p_value[p_value==0] = 0.00000000001\n",
    "    \n",
    "    # initiate Power Martingale\n",
    "    power_mart = np.zeros(alpha.shape)\n",
    "    \n",
    "    # initiate difference\n",
    "    diff_arr = np.zeros(alpha.shape)\n",
    "\n",
    "    # dummy multiplier\n",
    "    M = 0.\n",
    "\n",
    "    # iterrate for power martingale calculation\n",
    "    for i in range(L):\n",
    "    \n",
    "        # Calculate delta Array    \n",
    "        delta = np.log(eps) + (eps - 1.) * np.log(p_value[i])\n",
    "        \n",
    "        # Integrate for mix\n",
    "        delta_mix = simps(delta , eps)\n",
    "        \n",
    "        # update power martingale\n",
    "        M += delta_mix\n",
    "        \n",
    "        # Array\n",
    "        power_mart[i] = M\n",
    "        \n",
    "        # difference\n",
    "        diff_arr[i] = np.absolute(delta_mix)\n",
    "        \n",
    "        \n",
    "    return power_mart , diff_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Plugin Martingale\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to calculate Plugin Martingale:\n",
    "# ---------------------------------------\n",
    "# plugin_martingale_o function\n",
    "# Description: Calculates Power Martingale for outlier detection with a plugin variation\n",
    "# Input:\n",
    "#       train - numpy matrix containing the training data set\n",
    "#       test - Lnumpy matrix containing the testing data set\n",
    "#       alpha_flag - 1,2,3\n",
    "# Return:\n",
    "#       datpower_mart - Power Martingale Value\n",
    "#       diff_arr - Power Martingale Value Difference\n",
    "#\n",
    "def plugin_martingale(train , test , alpha_flag):\n",
    "    \n",
    "    # data mean\n",
    "    mean = np.average(train , axis = 0)\n",
    "    \n",
    "    # mean vector norm\n",
    "    mean_norm = np.linalg.norm(mean)\n",
    "\n",
    "    # strangenes reference\n",
    "    ref_alpha = np.linalg.norm(train.std(axis = 0)) + mean_norm\n",
    "    # ref_alpha = train.std(axis=0)\n",
    "\n",
    "     # Data shape\n",
    "    L = test.shape[0]\n",
    "    col = test.shape[1]\n",
    "    \n",
    "    # Only the distance strangeness is available for multivariate data\n",
    "    if col>1:\n",
    "        alpha_flag = 1\n",
    "\n",
    "    # alpha\n",
    "    if alpha_flag == 1:\n",
    "        alpha = np.linalg.norm(test , axis = 1) / ref_alpha\n",
    "        \n",
    "    elif alpha_flag == 2:\n",
    "        alpha = np.absolute(test - np.average(train)) /  train.std(axis=0)\n",
    "        \n",
    "    else:\n",
    "        alpha = alpha_calc(train , test)\n",
    "    \n",
    "    # p-value(randomised)\n",
    "    p_value = np.zeros(alpha.shape)\n",
    "\n",
    "    # iterrate for p-value calculation\n",
    "    for i in range(1,L):\n",
    "    \n",
    "        # end value\n",
    "        end = alpha[i]\n",
    "    \n",
    "        # alpha subset\n",
    "        alpha_sub = alpha[:i+1]\n",
    "\n",
    "        # number of elements\n",
    "        n = i + 1   \n",
    "    \n",
    "        # p-values calculation\n",
    "        p_value[i] = ( float(np.sum(alpha_sub > end)) + np.random.uniform() * np.sum(alpha_sub == end ) ) / float(n)\n",
    "    \n",
    "        # to avoid log zero\n",
    "        p_value[p_value==0] = 0.00000001\n",
    "        \n",
    "    # Extended sample\n",
    "    p_value_neg = - p_value\n",
    "    p_value_ref = 2.0 - p_value\n",
    "    \n",
    "    # initiate Power Martingale\n",
    "    power_mart = np.zeros(alpha.shape)\n",
    "    \n",
    "    # initiate difference\n",
    "    diff_arr = np.zeros(alpha.shape)\n",
    "\n",
    "    # dummy multiplier\n",
    "    M = 0.\n",
    "\n",
    "    # iterrate for plugin martingale calculation\n",
    "    for i in range(1,L):\n",
    "        \n",
    "        # samples\n",
    "        s1 = p_value_neg[:i]\n",
    "        s2 = p_value[:i]\n",
    "        s3 = p_value_ref[:i]\n",
    "        \n",
    "        # concatenation\n",
    "        s12 = np.concatenate((s1 , s2) , axis = 0)\n",
    "        sample = np.concatenate((s12 , s3) , axis  = 0)\n",
    "       \n",
    "        \n",
    "        # Estimate pdf\n",
    "        den = PDF(sample, bw_method='silverman')\n",
    "        \n",
    "        # Integral\n",
    "        A = den.integrate_box_1d(0,1)\n",
    "        \n",
    "        # Evaluate\n",
    "        f =  den.evaluate(p_value[i]) / A\n",
    "        delta = np.log(f)\n",
    "        M += delta\n",
    "        power_mart[i] = M \n",
    "        diff_arr[i] = delta\n",
    "    \n",
    "    # First Element\n",
    "    power_mart[0] = power_mart[1]   \n",
    "    \n",
    "    \n",
    "    return power_mart , diff_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Jump Rate Strangeness\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# alpha_calc function\n",
    "# Description: Calculates Alpha Values\n",
    "# Input:\n",
    "#       train - numpy matrix containing the training data set\n",
    "#       test - Lnumpy matrix containing the testing data set\n",
    "# Return:\n",
    "#       Alpha Values\n",
    "\n",
    "def alpha_calc(train , test):\n",
    "    \n",
    "    # initiation\n",
    "    train_d = np.zeros(train.shape)\n",
    "    test_d = np.zeros(test.shape)\n",
    "    \n",
    "    # Calculate refeence jump rate from training\n",
    "    for i in range(1,train_d.shape[0]):\n",
    "        train_d[i] = np.absolute(train[i] - train[i-1])\n",
    "    \n",
    "    # Calculate test jump rate\n",
    "    for i in range(1, test_d.shape[0]):\n",
    "        test_d[i] = np.absolute(test[i] - test[i-1])\n",
    "\n",
    "    return test_d / np.average(train_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Smoothing\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exponential Smoother:\n",
    "# ---------------------\n",
    "# smooth function\n",
    "# Description: Exponential Smoother\n",
    "# Input:\n",
    "#       y - Data to be smoothed\n",
    "#       alpha - alpha parameter\n",
    "# Return:\n",
    "#       x - smoothed values\n",
    "def smooth(y , alpha):\n",
    "    \n",
    "    # initiation of the filtered signal array\n",
    "    x = np.zeros(y.shape)\n",
    "    \n",
    "    # Data size\n",
    "    L = y.shape[0]\n",
    "    \n",
    "    # intiation\n",
    "    x[0] = 0.5 * (1. + alpha) * y[0]\n",
    "    \n",
    "    # Iterrate for new samples\n",
    "    for i in range(1,L):\n",
    "        x[i] = alpha * y[i] + (1. - alpha) * x[i - 1]\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preprocessing\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Open both training and test data sets:\n",
    "# -------------------------------------\n",
    "\n",
    "# training set \n",
    "train_raw = np.loadtxt(file_train, delimiter = ',') \n",
    "\n",
    "# test set\n",
    "test_raw = np.loadtxt(file_test , delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data preprocessing:\n",
    "# -------------------\n",
    "\n",
    "# Training data shape\n",
    "train_len = train_raw.shape[0]     \n",
    "train_col = train_raw.shape[1]\n",
    "\n",
    "# Test data shape\n",
    "test_len = test_raw.shape[0]\n",
    "test_col = test_raw.shape[1]\n",
    "\n",
    "\n",
    "# Normaliztion\n",
    "if (normal== 'y'):\n",
    "    train_norm = train_raw / train_raw.std(axis=0)\n",
    "    test_norm  = test_raw / test_raw.std(axis=0)\n",
    "    \n",
    "else:\n",
    "    train_norm = train_raw\n",
    "    test_norm = test_raw\n",
    "    \n",
    "\n",
    "# Difference\n",
    "if (dif!='No'):\n",
    "    \n",
    "    # Initiate arrays\n",
    "    train = np.zeros(train_norm.shape)\n",
    "    test  = np.zeros(test_norm.shape)\n",
    "    \n",
    "    # Training data\n",
    "    for i in range (dif, train_len):\n",
    "        train[i, :] = train_norm[i,:] - train_norm[ i - dif , : ]\n",
    "        \n",
    "    # Test data\n",
    "    for i in range (dif, test_len):\n",
    "        test[i, :] = test_norm[i,:] - test_norm[ i - dif , : ]    \n",
    "    \n",
    "    \n",
    "else:\n",
    "    train = train_norm\n",
    "    test  = test_norm      \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculation\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate the Martingales and change detection:\n",
    "# ----------------------------------------------\n",
    "\n",
    "# Fixed Epsilon\n",
    "if (mart == 'eps'):\n",
    "    martingale , cd_diff = power_martingale(train , test , eps , strg)\n",
    "    \n",
    "# Mixed Martingale\n",
    "elif (mart == 'mix'):\n",
    "    martingale , cd_diff = power_martingale_mix(train, test , res, strg)\n",
    "    \n",
    "# Plugin Martingale\n",
    "else:\n",
    "    martingale , cd_diff = plugin_martingale(train , test , strg)\n",
    "    \n",
    "# Smooth the change detection difference:\n",
    "cd_smooth = smooth(cd_diff , a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Output (.csv file)\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct the output data frame and export to a text file:\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Reshape arrays\n",
    "array_mar  = martingale.reshape((test_len,1))\n",
    "array_diff = cd_diff.reshape((test_len , 1))\n",
    "array_smooth = cd_smooth.reshape((test_len , 1))\n",
    "\n",
    "# Concatenate\n",
    "results_1 = np.concatenate((array_mar , array_diff) , axis  = 1)\n",
    "results_array = np.concatenate((results_1 , array_smooth) , axis = 1)\n",
    "\n",
    "# Data FRame and Export\n",
    "results_df = pd.DataFrame(results_array , columns = ['Martingale' , 'ChangeDetection' , 'SmoothedChangedDetection'])\n",
    "\n",
    "# Export file\n",
    "results_df.to_csv('ExchangeabilityMartingale.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
